{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Phase 1: Model Experimentation & Selection\n",
                "\n",
                "## Objective\n",
                "In this notebook, we will experiment with different approaches to solve the Toxicity Detection problem. We will start with a simple baseline and then move to a Deep Learning solution. The goal is to decide the final architecture and preprocessing steps for our production code.\n",
                "\n",
                "**Experiments:**\n",
                "1. **Baseline**: TF-IDF Vectorization + Logistic Regression.\n",
                "2. **Deep Learning**: LSTM (Long Short-Term Memory) with Keras.\n",
                "\n",
                "**Outcome:**\n",
                "At the end of this notebook, we will clearly state the configurations (Max Length, Vocab Size, Model Arch) that will be moved to `src/`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "d:\\Jeet\\projects\\Data_Science\\Project\\Projrct_Comment_Toxicity\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
                        "  if not hasattr(np, \"object\"):\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
                "\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.preprocessing.text import Tokenizer\n",
                "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
                "\n",
                "import os\n",
                "\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Preparation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded 159571 rows.\n",
                        "Train shape: (127656,)\n",
                        "Test shape: (31915,)\n"
                    ]
                }
            ],
            "source": [
                "# Load raw data\n",
                "DATA_PATH = '../data/raw/train.csv'\n",
                "\n",
                "if os.path.exists(DATA_PATH):\n",
                "    df = pd.read_csv(DATA_PATH)\n",
                "    # Minimal cleaning for experiment\n",
                "    df['comment_text'] = df['comment_text'].fillna('')\n",
                "    print(f\"Loaded {len(df)} rows.\")\n",
                "else:\n",
                "    print(\"Error: Data not found.\")\n",
                "\n",
                "# Target variable\n",
                "target_col = 'toxic'\n",
                "\n",
                "# Sample for faster experimentation (Optional - comment out for full run)\n",
                "# df = df.sample(20000, random_state=42)\n",
                "\n",
                "X = df['comment_text'].astype(str)\n",
                "y = df[target_col]\n",
                "\n",
                "# Split: 80% Train, 20% Test\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "print(f\"Train shape: {X_train.shape}\")\n",
                "print(f\"Test shape: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Baseline Model: TF-IDF + Logistic Regression\n",
                "Always start simple. If a simple model gives 95% accuracy, complex deep learning might be overkill."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Baseline Accuracy: 0.9576061413128623\n",
                        "\n",
                        "Classification Report (Baseline):\n",
                        "\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.96      0.99      0.98     28859\n",
                        "           1       0.90      0.62      0.74      3056\n",
                        "\n",
                        "    accuracy                           0.96     31915\n",
                        "   macro avg       0.93      0.81      0.86     31915\n",
                        "weighted avg       0.96      0.96      0.95     31915\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Vectorize\n",
                "vectorizer = TfidfVectorizer(max_features=5000)\n",
                "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
                "X_test_tfidf = vectorizer.transform(X_test)\n",
                "\n",
                "# Train\n",
                "lr_model = LogisticRegression(max_iter=1000)\n",
                "lr_model.fit(X_train_tfidf, y_train)\n",
                "\n",
                "# Evaluate\n",
                "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
                "print(\"Baseline Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
                "print(\"\\nClassification Report (Baseline):\\n\")\n",
                "print(classification_report(y_test, y_pred_lr))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Deep Learning Experiment: LSTM\n",
                "Now we try a specialized sequence model. LSTMs are great for understanding the context in text data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Data prepared. X_train_pad shape: (127656, 150)\n"
                    ]
                }
            ],
            "source": [
                "# Configuration (These are the Hyperparameters we define for production)\n",
                "MAX_VOCAB_SIZE = 20000  # Max unique words to keep\n",
                "MAX_LEN = 150           # Max length of a comment (based on EDA)\n",
                "EMBEDDING_DIM = 64      # Size of word vectors\n",
                "\n",
                "# 1. Tokenization\n",
                "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
                "tokenizer.fit_on_texts(X_train)\n",
                "\n",
                "# 2. Convert text to sequences\n",
                "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
                "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
                "\n",
                "# 3. Padding (make all sequences same length)\n",
                "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN)\n",
                "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN)\n",
                "\n",
                "print(f\"Data prepared. X_train_pad shape: {X_train_pad.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "d:\\Jeet\\projects\\Data_Science\\Project\\Projrct_Comment_Toxicity\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:100: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1mModel: \"sequential\"\u001b[0m\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
                            "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
                            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
                            "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ global_max_pooling1d            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
                            "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
                            "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
                            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
                            "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ global_max_pooling1d            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
                            "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
                            "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Define the Model Architecture\n",
                "model = Sequential([\n",
                "    Embedding(MAX_VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LEN),\n",
                "    Bidirectional(LSTM(64, return_sequences=True)), # Bidirectional learns context from both directions\n",
                "    tf.keras.layers.GlobalMaxPool1D(),              # Reduces dimensionality\n",
                "    Dense(64, activation='relu'),\n",
                "    Dropout(0.3),                                   # Prevents overfitting\n",
                "    Dense(1, activation='sigmoid')                  # Binary classification output\n",
                "])\n",
                "\n",
                "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/2\n",
                        "\u001b[1m3591/3591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 64ms/step - accuracy: 0.9549 - loss: 0.1288 - val_accuracy: 0.9622 - val_loss: 0.0994\n",
                        "Epoch 2/2\n",
                        "\u001b[1m3591/3591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 71ms/step - accuracy: 0.9678 - loss: 0.0874 - val_accuracy: 0.9637 - val_loss: 0.1013\n"
                    ]
                }
            ],
            "source": [
                "# Train (Using fewer epochs for experiment)\n",
                "# In production, we might use EarlyStopping and more epochs\n",
                "history = model.fit(\n",
                "    X_train_pad, y_train,\n",
                "    batch_size=32,\n",
                "    epochs=2,  # Keep it short for notebook experiment\n",
                "    validation_split=0.1\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[1m998/998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step\n",
                        "LSTM Accuracy: 0.9634654551151496\n",
                        "\n",
                        "Classification Report (LSTM):\n",
                        "\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.97      0.99      0.98     28859\n",
                        "           1       0.87      0.73      0.79      3056\n",
                        "\n",
                        "    accuracy                           0.96     31915\n",
                        "   macro avg       0.92      0.86      0.89     31915\n",
                        "weighted avg       0.96      0.96      0.96     31915\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Evaluate LSTM\n",
                "y_pred_probs = model.predict(X_test_pad)\n",
                "y_pred_lstm = (y_pred_probs > 0.5).astype(int)\n",
                "\n",
                "print(\"LSTM Accuracy:\", accuracy_score(y_test, y_pred_lstm))\n",
                "print(\"\\nClassification Report (LSTM):\\n\")\n",
                "print(classification_report(y_test, y_pred_lstm))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Final Decision & Conclusion\n",
                "\n",
                "**Comparison:**\n",
                "- Check F1-scores of class '1' (Toxic) for both models.\n",
                "- Deep Learning usually outperforms on larger datasets or more complex language structures.\n",
                "\n",
                "**Production Plan:**\n",
                "Based on these experiments, we will adopt the **LSTM approach** for our production codebase.\n",
                "\n",
                "**Parameters for `src/`:**\n",
                "- `MAX_WORDS` (Vocab) = 20,000\n",
                "- `MAX_LEN` = 150\n",
                "- `EMBEDDING_DIM` = 64\n",
                "- Architecture: Embedding -> Bi-LSTM -> GlobalMaxPool -> Dense -> Dropout -> Output"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Projrct_Comment_Toxicity",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
