import streamlit as st
import pandas as pd
import numpy as np
import os
from utils import ToxicityPredictor
from PIL import Image

# Page Config
st.set_page_config(
    page_title="SafeGuard: Toxicity Detection",
    page_icon="üõ°Ô∏è",
    layout="wide"
)

# Custom CSS
st.markdown("""
    <style>
    .main { padding-top: 1rem; }
    </style>
""", unsafe_allow_html=True)

@st.cache_resource
def get_predictor():
    return ToxicityPredictor()

def load_metrics():
    """Parses metrics.txt generated by evaluate.py"""
    metrics_path = os.path.join('results', 'metrics.txt')
    cm_path = os.path.join('results', 'confusion_matrix.png')
    
    metrics = {}
    if os.path.exists(metrics_path):
        with open(metrics_path, 'r') as f:
            for line in f:
                if ":" in line and "Classification Report" not in line:
                    key, val = line.split(":", 1)
                    metrics[key.strip()] = val.strip()
    
    return metrics, cm_path

def main():
    st.title("üõ°Ô∏è SafeGuard Dashboard")
    st.markdown("### End-to-End Toxicity Detection System")

    predictor = get_predictor()
    if predictor.model is None:
        st.error("Model not found. Please run `python src/train.py`.")
        return

    # --- TABS FOR ORGANIZED DASHBOARD ---
    tab1, tab2, tab3 = st.tabs(["üí¨ Prediction Playground", "üìÅ Batch Analysis", "üìà Insights & Performance"])

    # ==========================================
    # TAB 1: PREDICTION PLAYGROUND
    # ==========================================
    with tab1:
        col_main, col_samples = st.columns([2, 1])
        
        with col_samples:
            st.subheader("Test Cases")
            st.markdown("Select a sample to populate the text box:")
            
            sample_options = {
                "Custom Input": "",
                "Toxic: Direct Insult": "You are a complete idiot and should leave immediately.",
                "Toxic: Threat": "I am going to find you and hurt you.",
                "Safe: Positive Feedback": "I really learned a lot from this post, excellent work!",
                "Safe: Polite Disagreement": "I think you might be mistaken here, check the sources again.",
                "Ambiguous: Strong Language": "That performance was damn crazy!"
            }
            
            selected_sample = st.radio("Choose Example:", list(sample_options.keys()))
            default_text = sample_options[selected_sample]

        with col_main:
            st.subheader("Single Comment Analysis")
            text_input = st.text_area("Enter text to analyze:", value=default_text, height=200)
            
            if st.button("üîç Analyze Text", type="primary"):
                if text_input.strip():
                    with st.spinner("Processing semantics..."):
                        score = predictor.predict(text_input)
                    
                    # Result Display
                    st.divider()
                    c1, c2 = st.columns(2)
                    
                    with c1:
                        st.metric("Toxicity Probability", f"{score:.2%}")
                        st.progress(score)
                    
                    with c2:
                        if score > 0.5:
                            st.error("üö® **TOXIC DETECTED**")
                            st.write("Contains potential hate speech, harassment, or aggression.")
                        else:
                            st.success("‚úÖ **CONTENT SAFE**")
                            st.write("Content complies with community safety guidelines.")
                else:
                    st.warning("Please enter or select some text.")

    # ==========================================
    # TAB 2: BATCH ANALYSIS
    # ==========================================
    with tab2:
        st.header("Batch CSV Processing")
        st.markdown("Upload a CSV file containing a `comment_text` column to process thousands of comments at once.")
        
        uploaded_file = st.file_uploader("Upload CSV", type=['csv'])
        if uploaded_file:
            df = pd.read_csv(uploaded_file)
            if 'comment_text' in df.columns:
                st.info(f"Loaded {len(df)} comments.")
                if st.button("üöÄ Process Batch"):
                    with st.spinner("Running batch inference..."):
                        scores = predictor.predict_batch(df['comment_text'].astype(str).tolist())
                        df['toxicity_score'] = scores
                        df['prediction'] = ['TOXIC' if s > 0.5 else 'SAFE' for s in scores]
                        
                        st.dataframe(df.head())
                        
                        csv = df.to_csv(index=False).encode('utf-8')
                        st.download_button("üì• Download Results", csv, "predictions.csv", "text/csv")
            else:
                st.error("Column `comment_text` not found in CSV.")

    # ==========================================
    # TAB 3: INSIGHTS & PERFORMANCE
    # ==========================================
    with tab3:
        st.header("üìä Model Metrics & Data Insights")
        
        metrics, cm_path = load_metrics()
        
        # Row 1: Key Metrics
        m1, m2, m3, m4 = st.columns(4)
        m1.metric("Model Accuracy", metrics.get("Accuracy", "N/A"))
        m2.metric("Precision", metrics.get("Precision", "N/A"))
        m3.metric("Recall", metrics.get("Recall", "N/A"))
        m4.metric("F1 Score", metrics.get("F1 Score", "N/A"))
        
        st.divider()
        
        # Row 2: Visualizations
        col_viz1, col_viz2 = st.columns(2)
        
        with col_viz1:
            st.subheader("Confusion Matrix")
            if os.path.exists(cm_path):
                st.image(cm_path, use_container_width=True)
            else:
                st.info("Confusion matrix image not found in results/.")
                
        with col_viz2:
            st.subheader("Training Data Distribution")
            # Load actual stats from processed data if available
            y_train_path = os.path.join('data', 'processed', 'y_train.npy')
            if os.path.exists(y_train_path):
                y_train = np.load(y_train_path)
                toxic_cnt = np.sum(y_train)
                safe_cnt = len(y_train) - toxic_cnt
                
                chart_df = pd.DataFrame({
                    "Class": ["Toxic", "Safe"],
                    "Count": [toxic_cnt, safe_cnt]
                })
                st.bar_chart(chart_df.set_index("Class"), color="#ff4b4b")
                st.caption(f"Total Training Samples: {len(y_train):,}")
            else:
                st.info("Training statistics not available.")

if __name__ == "__main__":
    main()
